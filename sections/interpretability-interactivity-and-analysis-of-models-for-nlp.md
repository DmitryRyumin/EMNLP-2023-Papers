# EMNLP-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/blob/main/sections/phonology-morphology-and-word-segmentation.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/blob/main/sections/language-grounding-to-vision-robotics-and-beyond.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Interpretability, Interactivity, and Analysis of Models for NLP

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

<!-- 210, 299 -->
| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Dissecting Recall of Factual Associations in Auto-Regressive Language Models]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Interpreting Embedding Spaces by Conceptualization]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Norm of Word Embedding Encodes Information Gain]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Can LLMs Facilitate Interpretation of Pre-Trained Language Models?]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Can You Follow Me? Testing Situational Understanding for ChatGPT]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Absolute Position Embedding Learns Sinusoid-Like Waves for Attention based on Relative Position]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Statistical Depth for Ranking and Characterizing Transformer-based Text Embeddings]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Explaining Interactions between Text Spans]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Bridging Information-Theoretic and Geometric Compression in Language Models]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
| [Data Factors for Better Compositional Generalization]() |  | [![acl](https://img.shields.io/badge/pdf-ACL%20Anthology-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-main.423.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.07487-b31b1b.svg)](http://arxiv.org/abs/2310.07487) | :heavy_minus_sign: |
