# EMNLP-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/blob/main/sections/tutorial-abstracts.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers/blob/main/sections/industry-track.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## System Demonstrations

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs](https://aclanthology.org/2023.emnlp-demo.1) | [![GitHub](https://img.shields.io/github/stars/flairNLP/fabricator)](https://github.com/flairNLP/fabricator) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.1.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.09582-b31b1b.svg)](http://arxiv.org/abs/2309.09582) | :heavy_minus_sign: |
| [End-to-End Evaluation for Low-Latency Simultaneous Speech Translation](https://aclanthology.org/2023.emnlp-demo.2) | :heavy_minus_sign: | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.2.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03415-b31b1b.svg)](http://arxiv.org/abs/2308.03415) | :heavy_minus_sign: |
| [CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools](https://aclanthology.org/2023.emnlp-demo.3) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://reports.chatclimate.ai/) <br /> [![GitHub](https://img.shields.io/github/stars/EdisonNi-hku/chatreport)](https://github.com/EdisonNi-hku/chatreport) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.3.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15770-b31b1b.svg)](http://arxiv.org/abs/2307.15770) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Q5AzaKzPE4M) |
| [RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models](https://aclanthology.org/2023.emnlp-demo.4) | [![GitHub](https://img.shields.io/github/stars/yhoshi3/RaLLe)](https://github.com/yhoshi3/RaLLe) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.4.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10633-b31b1b.svg)](http://arxiv.org/abs/2308.10633) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JYbm75qnfTg) |
| [VIST5: An Adaptive, Retrieval-Augmented Language Model for Visualization-Oriented Dialog](https://aclanthology.org/2023.emnlp-demo.5) | [![GitHub](https://img.shields.io/github/stars/clause-bielefeld/VIST5)](https://github.com/clause-bielefeld/VIST5) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.5.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bsgaV7hjlGs) |
| [H2O Open Ecosystem for State-of-the-Art Large Language Models](https://aclanthology.org/2023.emnlp-demo.6) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gpt.h2o.ai/) <br /> [![GitHub](https://img.shields.io/github/stars/h2oai/h2ogpt)](https://github.com/h2oai/h2ogpt) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.6.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.13012-b31b1b.svg)](http://arxiv.org/abs/2310.13012) | :heavy_minus_sign: |
| [Koala: An Index for Quantifying Overlaps with Pre-Training Corpora](https://aclanthology.org/2023.emnlp-demo.7) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://koala-index.erc.monash.edu/) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.7.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14770-b31b1b.svg)](http://arxiv.org/abs/2303.14770) | :heavy_minus_sign: |
| [Sudowoodo: A Chinese Lyric Imitation System with Source Lyrics](https://aclanthology.org/2023.emnlp-demo.8) | [![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://sudowoodo.apps-hp.danlu.netease.com/) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.8.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04665-b31b1b.svg)](http://arxiv.org/abs/2308.04665) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u5BBT_j1L5M) |
| [ConvLab-3: A Flexible Dialogue System Toolkit based on a Unified Data Format](https://aclanthology.org/2023.emnlp-demo.9) | [![GitHub](https://img.shields.io/github/stars/ConvLab/ConvLab-3)](https://github.com/ConvLab/ConvLab-3) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.9.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17148-b31b1b.svg)](http://arxiv.org/abs/2211.17148) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=t6HVTJCeGLo) |
| [FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge](https://aclanthology.org/2023.emnlp-demo.10) | :heavy_minus_sign: | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.10.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.17119-b31b1b.svg)](http://arxiv.org/abs/2310.17119) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NapJFUlkPdQ) |
| [YATO: Yet Another Deep Learning based Text Analysis Open Toolkit](https://aclanthology.org/2023.emnlp-demo.11) | [![GitHub](https://img.shields.io/github/stars/jiesutd/YATO)](https://github.com/jiesutd/YATO) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.11.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.13877-b31b1b.svg)](http://arxiv.org/abs/2209.13877) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/playlist?list=PLJ0mhzMcRuDUlTkzBfAftOqiJRxYTTjXH) |
| [Spacerini: Plug-and-Play Search Engines with Pyserini and Hugging Face](https://aclanthology.org/2023.emnlp-demo.12) | [![GitHub](https://img.shields.io/github/stars/castorini/hf-spacerini)](https://github.com/castorini/hf-spacerini) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.12.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14534-b31b1b.svg)](http://arxiv.org/abs/2302.14534) | :heavy_minus_sign: |
| [Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning](https://aclanthology.org/2023.emnlp-demo.13) | [![GitHub](https://img.shields.io/github/stars/adapter-hub/adapters)](https://github.com/adapter-hub/adapters) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.13.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.11077-b31b1b.svg)](http://arxiv.org/abs/2311.11077) | :heavy_minus_sign: |
| [INTELMO: Enhancing Models' Adoption of Interactive Interfaces](https://aclanthology.org/2023.emnlp-demo.14) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://intelmo.vercel.app/) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.14.pdf) | :heavy_minus_sign: |
| [Humanoid Agents: Platform for Simulating Human-Like Generative Agents](https://aclanthology.org/2023.emnlp-demo.15) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.humanoidagents.com/) <br /> [![GitHub](https://img.shields.io/github/stars/HumanoidAgents/HumanoidAgents)](https://github.com/HumanoidAgents/HumanoidAgents) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.15.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.05418-b31b1b.svg)](http://arxiv.org/abs/2310.05418) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vQkOf-zS2Y0) |
| [TP-Detector: Detecting Turning Points in the Engineering Process of Large-Scale Projects](https://aclanthology.org/2023.emnlp-demo.16) | [![GitHub](https://img.shields.io/github/stars/smile577/tpd)](https://github.com/smile577/tpd) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.16.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FH3av84I-Kg) |
| [CLEVA: Chinese Language Models EVAluation Platform](https://aclanthology.org/2023.emnlp-demo.17) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.lavicleva.com/) <br /> [![GitHub](https://img.shields.io/github/stars/LaVi-Lab/CLEVA)](https://github.com/LaVi-Lab/CLEVA) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.17.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04813-b31b1b.svg)](http://arxiv.org/abs/2308.04813) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TvrJoU6v-Sg) |
| [DOPA METER - A Tool Suite for Metrical Document Profiling and Aggregation](https://aclanthology.org/2023.emnlp-demo.18) | [![GitHub](https://img.shields.io/github/stars/dopameter/dopameter)](https://github.com/dopameter/dopameter) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.18.pdf) | :heavy_minus_sign: |
| [Muted: Multilingual Targeted Offensive Speech Identification and Visualization](https://aclanthology.org/2023.emnlp-demo.19) | :heavy_minus_sign: | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.19.pdf) | :heavy_minus_sign: |
| [Gentopia.AI: A Collaborative Platform for Tool-Augmented LLMs](https://aclanthology.org/2023.emnlp-demo.20) | [![GitHub](https://img.shields.io/github/stars/Gentopia-AI/Gentopia)](https://github.com/Gentopia-AI/Gentopia) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.20.pdf) | :heavy_minus_sign: |
| [MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models](https://aclanthology.org/2023.emnlp-demo.21) | [![GitHub](https://img.shields.io/github/stars/microsoft/muzic)](https://github.com/microsoft/muzic) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.21.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.11954-b31b1b.svg)](http://arxiv.org/abs/2310.11954) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tpNynjdcBqA) |
| [SentAlign: Accurate and Scalable Sentence Alignment](https://aclanthology.org/2023.emnlp-demo.22) | [![GitHub](https://img.shields.io/github/stars/steinst/sentalign)](https://github.com/steinst/sentalign) | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.22.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.08982-b31b1b.svg)](http://arxiv.org/abs/2311.08982) | :heavy_minus_sign: |
| [QACheck: A Demonstration System for Question-Guided Multi-Hop Fact-Checking](https://aclanthology.org/2023.emnlp-demo.23) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.23.pdf) |  |
| [RobustQA: A Framework for Adversarial Text Generation Analysis on Question Answering Systems](https://aclanthology.org/2023.emnlp-demo.24) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.24.pdf) |  |
| [Kandinsky: An Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion](https://aclanthology.org/2023.emnlp-demo.25) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.25.pdf) |  |
| [NewsRecLib: A PyTorch-Lightning Library for Neural News Recommendation](https://aclanthology.org/2023.emnlp-demo.26) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.26.pdf) |  |
| [MiniChain: A Small Library for Coding with Large Language Models](https://aclanthology.org/2023.emnlp-demo.27) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.27.pdf) |  |
| [Okapi: Instruction-Tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback](https://aclanthology.org/2023.emnlp-demo.28) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.28.pdf) |  |
| [SAGEViz: SchemA GEneration and Visualization](https://aclanthology.org/2023.emnlp-demo.29) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.29.pdf) |  |
| [Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation](https://aclanthology.org/2023.emnlp-demo.30) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.30.pdf) |  |
| [InsightPilot: An LLM-Empowered Automated Data Exploration System](https://aclanthology.org/2023.emnlp-demo.31) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.31.pdf) |  |
| [SynJax: Structured Probability Distributions for JAX](https://aclanthology.org/2023.emnlp-demo.32) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.32.pdf) |  |
| [RESIN-EDITOR: A Schema-Guided Hierarchical Event Graph Visualizer and Editor](https://aclanthology.org/2023.emnlp-demo.33) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.33.pdf) |  |
| [DRGCoder: Explainable Clinical Coding for the Early Prediction of Diagnostic-Related Groups](https://aclanthology.org/2023.emnlp-demo.34) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.34.pdf) |  |
| [CAMRA: Copilot for AMR Annotation](https://aclanthology.org/2023.emnlp-demo.35) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.35.pdf) |  |
| [Reaction Miner: An Integrated System for Chemical Reaction Extraction from Textual Data](https://aclanthology.org/2023.emnlp-demo.36) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.36.pdf) |  |
| [CHAMP: Efficient Annotation and Consolidation of Cluster Hierarchies](https://aclanthology.org/2023.emnlp-demo.37) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.37.pdf) |  |
| [Prompt2Model: Generating Deployable Models from Natural Language Instructions](https://aclanthology.org/2023.emnlp-demo.38) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.38.pdf) |  |
| [NewsSense: Reference-Free Verification via Cross-Document Comparison](https://aclanthology.org/2023.emnlp-demo.39) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.39.pdf) |  |
| [NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails](https://aclanthology.org/2023.emnlp-demo.40) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.40.pdf) |  |
| [LM-Polygraph: Uncertainty Estimation for Language Models](https://aclanthology.org/2023.emnlp-demo.41) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.41.pdf) |  |
| [Descriptive Knowledge Graph in Biomedical Domain](https://aclanthology.org/2023.emnlp-demo.42) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.42.pdf) |  |
| [Prompterator: Iterate Efficiently towards more Effective Prompts](https://aclanthology.org/2023.emnlp-demo.43) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.43.pdf) |  |
| [ZhuJiu: A Multi-Dimensional, Multi-Faceted Chinese Benchmark for Large Language Models](https://aclanthology.org/2023.emnlp-demo.44) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.44.pdf) |  |
| [PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-Rich Scientific Documents](https://aclanthology.org/2023.emnlp-demo.45) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.45.pdf) |  |
| [OmniEvent: A Comprehensive, Fair, and Easy-to-use Toolkit for Event Understanding](https://aclanthology.org/2023.emnlp-demo.46) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.46.pdf) |  |
| [CocoSciSum: A Scientific Summarization Toolkit with Compositional Controllability](https://aclanthology.org/2023.emnlp-demo.47) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.47.pdf) |  |
| [CoLLiE: Collaborative Training of Large Language Models in an Efficient Way](https://aclanthology.org/2023.emnlp-demo.48) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.48.pdf) |  |
| [Video-LLaMA: An Instruction-Tuned Audio-Visual Language Model for Video Understanding](https://aclanthology.org/2023.emnlp-demo.49) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.49.pdf) |  |
| [SummHelper: Collaborative Human-Computer Summarization](https://aclanthology.org/2023.emnlp-demo.50) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.50.pdf) |  |
| [ModelScope-Agent: Building Your Customizable Agent System with Open-Source Large Language Models](https://aclanthology.org/2023.emnlp-demo.51) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.51.pdf) |  |
| [EfficientOCR: An Extensible, Open-Source Package for Efficiently Digitizing World Knowledge](https://aclanthology.org/2023.emnlp-demo.52) |  | [![acl](https://img.shields.io/badge/pdf-acl-CBCBCC.svg)](https://aclanthology.org/2023.emnlp-demo.52.pdf) |  |
