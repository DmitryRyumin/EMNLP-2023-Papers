[
  {
    "title": "Models See Hallucinations: Evaluating the Factuality in Video Captioning",
    "base_url": "https://aclanthology.org/2023.emnlp-main.723",
    "title_page": "",
    "repo": "PKULiuHui/FactVC",
    "web_page": null,
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": "2303.02961",
    "youtube_id": null,
    "section": "Language Grounding to Vision, Robotics and Beyond"
  },
  {
    "title": "Describe Me an Auklet: Generating Grounded Perceptual Category Descriptions",
    "base_url": "https://aclanthology.org/2023.emnlp-main.580",
    "title_page": "",
    "repo": "GU-CLASP/describe-me-an-auklet",
    "web_page": null,
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": null,
    "youtube_id": null,
    "section": "Language Grounding to Vision, Robotics and Beyond"
  },
  {
    "title": "Reading Books is Great, but not if You are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms",
    "base_url": "https://aclanthology.org/2023.emnlp-main.57",
    "title_page": "",
    "repo": "wade3han/normlens",
    "web_page": "https://seungjuhan.me/normlens/",
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": "2310.10418",
    "youtube_id": null,
    "section": "Language Grounding to Vision, Robotics and Beyond"
  },
  {
    "title": "Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models",
    "base_url": "https://aclanthology.org/2023.emnlp-main.660",
    "title_page": "",
    "repo": "MichiganNLP/Bridging_the_Digital_Divide",
    "web_page": null,
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": "2311.05746",
    "youtube_id": null,
    "section": "Language Grounding to Vision, Robotics and Beyond"
  },
  {
    "title": "3DRP-Net: 3D Relative Position-Aware Network for 3D Visual Grounding",
    "base_url": "https://aclanthology.org/2023.emnlp-main.656",
    "title_page": "",
    "repo": null,
    "web_page": null,
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": "2307.13363",
    "youtube_id": null,
    "section": "Language Grounding to Vision, Robotics and Beyond"
  },
  {
    "title": "Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge",
    "base_url": "https://aclanthology.org/2023.emnlp-main.304",
    "title_page": "",
    "repo": "PlusLabNLP/ENVISION",
    "web_page": null,
    "github_page": null,
    "demo_page": null,
    "paper_thecvf": ".pdf",
    "paper_arxiv_id": "2310.15066",
    "youtube_id": "t_yDXUriRZo",
    "section": "Language Grounding to Vision, Robotics and Beyond"
  }
]